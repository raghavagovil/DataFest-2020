{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/raghavagovil/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Warming up PyWSD (takes ~10 secs)... took 11.499523162841797 secs.\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import xlrd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pywsd.utils import lemmatize_sentence\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Only taxation and ri0t mongering is their expe...</td>\n",
       "      <td>Sat Mar 21 07:06:21 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I like my women like I like my Coronavirus cur...</td>\n",
       "      <td>Sat Mar 21 07:06:26 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Scammers may use fake emails or texts to get y...</td>\n",
       "      <td>Sat Mar 21 07:06:27 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"Map shows locations of airports where TSA off...</td>\n",
       "      <td>Sat Mar 21 07:06:27 +0000 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"Homeschooling experts offer advice for parent...</td>\n",
       "      <td>Sat Mar 21 07:06:27 +0000 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Only taxation and ri0t mongering is their expe...   \n",
       "1  I like my women like I like my Coronavirus cur...   \n",
       "2  Scammers may use fake emails or texts to get y...   \n",
       "3  \"Map shows locations of airports where TSA off...   \n",
       "4  \"Homeschooling experts offer advice for parent...   \n",
       "\n",
       "                       created_at  \n",
       "0  Sat Mar 21 07:06:21 +0000 2020  \n",
       "1  Sat Mar 21 07:06:26 +0000 2020  \n",
       "2  Sat Mar 21 07:06:27 +0000 2020  \n",
       "3  Sat Mar 21 07:06:27 +0000 2020  \n",
       "4  Sat Mar 21 07:06:27 +0000 2020  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in the data \n",
    "pd.set_option('display.max_columns', 500)\n",
    "tweets = pd.read_csv('kevin_40k.csv', encoding = 'cp1252')\n",
    "tweets = tweets[['text', 'created_at']]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence) \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(tweets.shape[0]): \n",
    "    scores.append(sentiment_analyzer_scores(str(tweets.iloc[i,])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'neg': 0.087, 'neu': 0.913, 'pos': 0.0, 'compound': -0.2023},\n",
       " {'neg': 0.0, 'neu': 0.717, 'pos': 0.283, 'compound': 0.7579},\n",
       " {'neg': 0.129, 'neu': 0.871, 'pos': 0.0, 'compound': -0.4767},\n",
       " {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0},\n",
       " {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0},\n",
       " {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0},\n",
       " {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0},\n",
       " {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0},\n",
       " {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0},\n",
       " {'neg': 0.0, 'neu': 0.872, 'pos': 0.128, 'compound': 0.4215}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list to df\n",
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Only taxation and ri0t mongering is their expe...</td>\n",
       "      <td>Sat Mar 21 07:06:21 +0000 2020</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I like my women like I like my Coronavirus cur...</td>\n",
       "      <td>Sat Mar 21 07:06:26 +0000 2020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Scammers may use fake emails or texts to get y...</td>\n",
       "      <td>Sat Mar 21 07:06:27 +0000 2020</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"Map shows locations of airports where TSA off...</td>\n",
       "      <td>Sat Mar 21 07:06:27 +0000 2020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"Homeschooling experts offer advice for parent...</td>\n",
       "      <td>Sat Mar 21 07:06:27 +0000 2020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Only taxation and ri0t mongering is their expe...   \n",
       "1  I like my women like I like my Coronavirus cur...   \n",
       "2  Scammers may use fake emails or texts to get y...   \n",
       "3  \"Map shows locations of airports where TSA off...   \n",
       "4  \"Homeschooling experts offer advice for parent...   \n",
       "\n",
       "                       created_at    neg    neu    pos  compound  \n",
       "0  Sat Mar 21 07:06:21 +0000 2020  0.087  0.913  0.000   -0.2023  \n",
       "1  Sat Mar 21 07:06:26 +0000 2020  0.000  0.717  0.283    0.7579  \n",
       "2  Sat Mar 21 07:06:27 +0000 2020  0.129  0.871  0.000   -0.4767  \n",
       "3  Sat Mar 21 07:06:27 +0000 2020  0.000  1.000  0.000    0.0000  \n",
       "4  Sat Mar 21 07:06:27 +0000 2020  0.000  1.000  0.000    0.0000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final tweets df with sentiment scores\n",
    "tweets = pd.concat([tweets.reset_index(drop=True), scores_df], axis=1)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding phrases in text\n",
    "donald_trump = sum(tweets['text'].str.contains('donald trump', case = False).astype(int))\n",
    "fake_news = sum(tweets['text'].str.contains('fake news', case = False).astype(int))\n",
    "united_states = sum(tweets['text'].str.contains('united_states', case = False).astype(int))\n",
    "news = sum(tweets['text'].str.contains('news', case = False).astype(int))\n",
    "media = sum(tweets['text'].str.contains('media', case = False).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
